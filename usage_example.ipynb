{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "In this notebook, We will show the usage of the **GANBLR** models.\n",
    "\n",
    "Currently, the following ganblr models are available in this package:\n",
    "\n",
    "- GANBLR\n",
    "- GANBLR++\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GANBLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load the data\n",
    "\n",
    "The first step is to get the data we will use. For `GANBLR`, the data must be discrete. \n",
    "\n",
    "In this case, with the built-in `get_demo_data` method, we can get the discrete `adult` data in the format of `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr import get_demo_data\n",
    "\n",
    "df = get_demo_data('adult')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Train the GANBLR Model\n",
    "\n",
    "Next, we will use `sklearn.model_selection.train_test_split` to split the data into training and test sets, then fit the training set into the `GANBLR` model in order to train the model.\n",
    "\n",
    "Note that the `GANBLR` class has build-in `sklearn.preprocessing.OrdinalEncoder` and `sklearn.preprocessing.LabelEncoder` to convert the data format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = df.iloc[:,:-1], df.iloc[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr.models import GANBLR\n",
    "model = GANBLR()\n",
    "model.fit(X_train, y_train, k = 0, epochs = 10, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Generate the synthetic data\n",
    "\n",
    "Once the model is ready, we can use `GANBLR.sample` method to sample some synthetic data.\n",
    "\n",
    "We can use the `size` parameter to specify the number of samples we want to generate. If we do not specify, it will generate the same number as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "\n",
    "syn_data = model.sample(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{type(syn_data)}, {syn_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(data = syn_data, columns=df.columns).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. TSTR evaluation\n",
    "\n",
    "Finally, as we did in our paper, we will perform a simple TSTR(Train on Synthetic, Test on Real) evaluation to demonstrate the performance of our generated data.\n",
    "\n",
    "We will evaluate on three models from sklearn, `LogisticRegression`, `RandomForest`, and `MLPClassifier`. \n",
    "\n",
    "TRTR(Train on Real, Test on Real) will be used as the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_lr = model.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = model.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf = model.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "ohe = OneHotEncoder(handle_unknown='ignore')\n",
    "lbe = LabelEncoder()\n",
    "X_train_ohe = ohe.fit_transform(X_train)\n",
    "X_test_ohe = ohe.transform(X_test)\n",
    "y_train_lbe = lbe.fit_transform(y_train)\n",
    "y_test_lbe = lbe.transform(y_test)\n",
    "\n",
    "trtr_score_lr  = LogisticRegression().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(X_train, y_train_lbe).score(X_test, y_test_lbe)\n",
    "trtr_score_mlp = MLPClassifier().fit(X_train_ohe, y_train_lbe).score(X_test_ohe, y_test_lbe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', acc_score_lr, acc_score_rf, acc_score_mlp],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP'])\n",
    "df_evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GANBLR++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Load the data\n",
    "\n",
    "Unlike `GANBLR`, which can only handle discrete data, `GANBLR++` can handle numerical data as well.\n",
    "\n",
    "In this case, to test `GANBLR++`, we use the built-in `get_demo_data` to get the raw `adult` data in the format of `pandas.DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr import get_demo_data\n",
    "df = get_demo_data('adult-raw')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Train the GANBLR++ model\n",
    "\n",
    "Next, we will use `sklearn.model_selection.train_test_split` to split the data into training and test sets, then fit the training set into the `GANBLRPP` model in order to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = df.values[:,:-1], df.values[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANBLR++ takes an additional parameter `numerical_columns` to tell the model which columns are numerical data. \n",
    "\n",
    "Numerical_columns is a list of integers indicating the indexes of numerical columns. \n",
    "\n",
    "In most cases, it can be obtained with the following code, but sometimes we still need to specify it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def is_numerical(dtype):\n",
    "    '''\n",
    "    if the type is one of ['signed-integer', 'unsigned-integer', 'floating point'], we reconginze it as a numerical one.\n",
    "    \n",
    "    Reference: https://numpy.org/doc/stable/reference/generated/numpy.dtype.kind.html#numpy.dtype.kind\n",
    "    '''\n",
    "    return dtype.kind in 'iuf'\n",
    "\n",
    "column_is_numerical = df.dtypes.apply(is_numerical).values\n",
    "numerical_columns = np.argwhere(column_is_numerical).ravel()\n",
    "numerical_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Generate the synthetic data\n",
    "\n",
    "Once the model is ready, we can use `GANBLRPP.sample` method to sample some synthetic data.\n",
    "\n",
    "We can use the `size` parameter to specify the number of samples we want to generate. If we do not specify, it will generate the same number as the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr.models import GANBLRPP\n",
    "ganblrpp = GANBLRPP(numerical_columns)\n",
    "ganblrpp.fit(X_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "syn_data = ganblrpp.sample(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(syn_data, columns=df.columns).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. TSTR evaluation\n",
    "\n",
    "Finally, as we did in our paper, we will perform a simple TSTR(Train on Synthetic, Test on Real) evaluation to demonstrate the performance of our generated data.\n",
    "\n",
    "We will evaluate on three models from sklearn, `LogisticRegression`, `RandomForest`, and `MLPClassifier`. \n",
    "\n",
    "TRTR(Train on Real, Test on Real) will be used as the baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_score_lr  = ganblrpp.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = ganblrpp.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf  = ganblrpp.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "catgorical_columns = list(set(range(X_train.shape[1])) - set(numerical_columns))  \n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_train_ohe = ohe.fit_transform(X_train[:,catgorical_columns])\n",
    "X_test_ohe  = ohe.transform(X_test[:,catgorical_columns])\n",
    "X_train_num = X_train[:,numerical_columns]\n",
    "X_test_num  = X_test[:,numerical_columns]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_concat = scaler.fit_transform(np.hstack([X_train_num, X_train_ohe]))\n",
    "X_test_concat  = scaler.transform(np.hstack([X_test_num, X_test_ohe]))\n",
    "\n",
    "lbe = LabelEncoder()\n",
    "y_train_lbe = lbe.fit_transform(y_train)\n",
    "y_test_lbe = lbe.transform(y_test)\n",
    "\n",
    "trtr_score_lr = LogisticRegression().fit(X_train_concat, y_train).score(X_test_concat, y_test)\n",
    "trtr_score_rf = RandomForestClassifier().fit(X_train_concat, y_train).score(X_test_concat, y_test)\n",
    "trtr_score_mlp = MLPClassifier().fit(X_train_concat, y_train).score(X_test_concat, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', acc_score_lr, acc_score_rf, acc_score_mlp],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp]\n",
    "], columns=['Evaluated Item', 'LR', 'RF', 'MLP'])\n",
    "df_evaluate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbedb5fa720de9fc907ceb56d89ea952339fe8fd12ba55975f895c345e9c974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
