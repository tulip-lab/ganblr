{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  workclass  fnlwgt  education  education-num  marital-status  \\\n",
       "0    6          7       0          9              2               4   \n",
       "1    7          6       0          9              2               2   \n",
       "2    6          4       0         11              5               0   \n",
       "3    7          4       0          1              0               2   \n",
       "4    4          4       0          9              2               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           1             1     4    1            13             0   \n",
       "1           4             0     4    1             0             0   \n",
       "2           6             1     4    1             0             0   \n",
       "3           6             0     2    1             0             0   \n",
       "4          10             5     2    0             0             0   \n",
       "\n",
       "   hours-per-week  native-country  class  \n",
       "0               2              39      0  \n",
       "1               0              39      0  \n",
       "2               2              39      0  \n",
       "3               2              39      0  \n",
       "4               2               5      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ganblr.utils import get_demo_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = get_demo_data('adult') #Optional: adult or car\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = OrdinalEncoder(dtype=int).fit_transform(df)\n",
    "x, y = data[:,:-1], data[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 int32\n",
      "764/764 [==============================] - 2s 654us/step - loss: 0.4252 - accuracy: 0.8050\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 0.3985 - accuracy: 0.8670\n",
      "764/764 [==============================] - 1s 436us/step\n",
      "764/764 [==============================] - 1s 654us/step - loss: 4.2390 - accuracy: 0.8569\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.2877 - accuracy: 0.8855\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 4.2712 - accuracy: 0.8644\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.8932 - accuracy: 0.7460\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 1s 644us/step - loss: 3.4082 - accuracy: 0.8672\n",
      "1222/1222 [==============================] - 1s 562us/step - loss: 1.0113 - accuracy: 0.8144\n",
      "764/764 [==============================] - 0s 430us/step\n",
      "764/764 [==============================] - 1s 643us/step - loss: 3.7352 - accuracy: 0.8687\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 1.5066 - accuracy: 0.6792\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.6152 - accuracy: 0.8705\n",
      "1222/1222 [==============================] - 1s 557us/step - loss: 0.7860 - accuracy: 0.7986\n",
      "764/764 [==============================] - 0s 430us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 4.0589 - accuracy: 0.8705\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.6171 - accuracy: 0.7958\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 1s 653us/step - loss: 3.3642 - accuracy: 0.8709\n",
      "1222/1222 [==============================] - 1s 567us/step - loss: 1.0579 - accuracy: 0.7348\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 643us/step - loss: 3.7582 - accuracy: 0.8702\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 0.7043 - accuracy: 0.8352\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 4.5533 - accuracy: 0.8715\n",
      "1222/1222 [==============================] - 1s 572us/step - loss: 0.2278 - accuracy: 0.9217\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 4.5588 - accuracy: 0.8717\n",
      "1222/1222 [==============================] - 1s 573us/step - loss: 0.5183 - accuracy: 0.8756\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 659us/step - loss: 5.6343 - accuracy: 0.8714\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 1.4652 - accuracy: 0.6862\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 2s 650us/step - loss: 3.7617 - accuracy: 0.8726\n",
      "1222/1222 [==============================] - 1s 577us/step - loss: 0.8611 - accuracy: 0.7506\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 640us/step - loss: 4.0801 - accuracy: 0.8723\n",
      "1222/1222 [==============================] - 1s 584us/step - loss: 2.1780 - accuracy: 0.6661\n",
      "764/764 [==============================] - 0s 441us/step\n",
      "764/764 [==============================] - 1s 654us/step - loss: 4.6206 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 611us/step - loss: 0.5004 - accuracy: 0.8365\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 4.5088 - accuracy: 0.8723\n",
      "1222/1222 [==============================] - 1s 566us/step - loss: 0.2917 - accuracy: 0.8909\n",
      "764/764 [==============================] - 0s 429us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 4.4448 - accuracy: 0.8718\n",
      "1222/1222 [==============================] - 1s 573us/step - loss: 1.3429 - accuracy: 0.6912\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 652us/step - loss: 3.3397 - accuracy: 0.8718\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 0.1675 - accuracy: 0.9329\n",
      "764/764 [==============================] - 0s 430us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 4.3143 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 1.6461 - accuracy: 0.5758\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 2.6226 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 623us/step - loss: 0.4695 - accuracy: 0.8793\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 1s 671us/step - loss: 5.6002 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 565us/step - loss: 0.9790 - accuracy: 0.8195\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 2s 650us/step - loss: 5.0907 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 1.3628 - accuracy: 0.7189\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 653us/step - loss: 3.1796 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.4312 - accuracy: 0.8539\n",
      "764/764 [==============================] - 0s 454us/step\n",
      "764/764 [==============================] - 1s 648us/step - loss: 4.1668 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 566us/step - loss: 0.9225 - accuracy: 0.7256\n",
      "764/764 [==============================] - 0s 431us/step\n",
      "764/764 [==============================] - 2s 647us/step - loss: 3.3454 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.9831 - accuracy: 0.7939\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 3.8161 - accuracy: 0.8726\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.3361 - accuracy: 0.8886\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 660us/step - loss: 4.3772 - accuracy: 0.8721\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 2.4363 - accuracy: 0.5945\n",
      "764/764 [==============================] - 0s 435us/step\n",
      "764/764 [==============================] - 2s 644us/step - loss: 3.1583 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.7379 - accuracy: 0.7442\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 654us/step - loss: 3.4731 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 590us/step - loss: 1.0855 - accuracy: 0.8292\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 652us/step - loss: 4.7721 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 2.4012 - accuracy: 0.6177\n",
      "764/764 [==============================] - 0s 443us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.6056 - accuracy: 0.8715\n",
      "1222/1222 [==============================] - 1s 561us/step - loss: 0.4419 - accuracy: 0.8489\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 2s 644us/step - loss: 3.7394 - accuracy: 0.8718\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 1.0146 - accuracy: 0.7413\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 4.4474 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 595us/step - loss: 0.5210 - accuracy: 0.7996\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 1s 645us/step - loss: 3.4377 - accuracy: 0.8731\n",
      "1222/1222 [==============================] - 1s 565us/step - loss: 2.0382 - accuracy: 0.6674\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 647us/step - loss: 2.7804 - accuracy: 0.8717\n",
      "1222/1222 [==============================] - 1s 572us/step - loss: 0.2442 - accuracy: 0.9111\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 1s 649us/step - loss: 4.5777 - accuracy: 0.8709\n",
      "1222/1222 [==============================] - 1s 635us/step - loss: 1.3044 - accuracy: 0.6506\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 652us/step - loss: 3.0940 - accuracy: 0.8735\n",
      "1222/1222 [==============================] - 1s 574us/step - loss: 1.4688 - accuracy: 0.6767\n",
      "764/764 [==============================] - 0s 443us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 2.9951 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 1.3290 - accuracy: 0.7322\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.4871 - accuracy: 0.8728\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 1.2032 - accuracy: 0.7363\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 644us/step - loss: 2.9337 - accuracy: 0.8726\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 0.9091 - accuracy: 0.6980\n",
      "764/764 [==============================] - 0s 439us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.0020 - accuracy: 0.8721\n",
      "1222/1222 [==============================] - 1s 567us/step - loss: 0.3119 - accuracy: 0.8873\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 4.2537 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 2.3107 - accuracy: 0.5830\n",
      "764/764 [==============================] - 0s 442us/step\n",
      "764/764 [==============================] - 1s 650us/step - loss: 2.4411 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 0.6719 - accuracy: 0.7568\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.0287 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 0.5370 - accuracy: 0.8127\n",
      "764/764 [==============================] - 0s 521us/step\n",
      "764/764 [==============================] - 2s 647us/step - loss: 3.0689 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 575us/step - loss: 1.4512 - accuracy: 0.6541\n",
      "764/764 [==============================] - 0s 434us/step\n",
      "764/764 [==============================] - 1s 641us/step - loss: 3.5562 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 587us/step - loss: 1.3128 - accuracy: 0.6943\n",
      "764/764 [==============================] - 0s 446us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 4.0402 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 563us/step - loss: 0.7385 - accuracy: 0.7748\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.2371 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 580us/step - loss: 0.6133 - accuracy: 0.7785\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 3.5593 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 566us/step - loss: 1.0496 - accuracy: 0.7022\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 644us/step - loss: 3.1428 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 1.9697 - accuracy: 0.5866\n",
      "764/764 [==============================] - 0s 441us/step\n",
      "764/764 [==============================] - 2s 657us/step - loss: 2.8294 - accuracy: 0.8721\n",
      "1222/1222 [==============================] - 1s 574us/step - loss: 0.5476 - accuracy: 0.8560\n",
      "764/764 [==============================] - 0s 445us/step\n",
      "764/764 [==============================] - 1s 648us/step - loss: 4.3829 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 588us/step - loss: 0.5292 - accuracy: 0.7989\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 3.2950 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 600us/step - loss: 0.7517 - accuracy: 0.8089\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.5390 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 1.3826 - accuracy: 0.6721\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 652us/step - loss: 2.9883 - accuracy: 0.8715\n",
      "1222/1222 [==============================] - 1s 565us/step - loss: 0.6992 - accuracy: 0.7793\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 657us/step - loss: 3.7674 - accuracy: 0.8723\n",
      "1222/1222 [==============================] - 1s 567us/step - loss: 0.8664 - accuracy: 0.7152\n",
      "764/764 [==============================] - 0s 445us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.1186 - accuracy: 0.8726\n",
      "1222/1222 [==============================] - 1s 578us/step - loss: 2.0436 - accuracy: 0.7119\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.0537 - accuracy: 0.8714\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 0.5571 - accuracy: 0.7924\n",
      "764/764 [==============================] - 0s 439us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 3.2301 - accuracy: 0.8723\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 1.4385 - accuracy: 0.7093\n",
      "764/764 [==============================] - 0s 440us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.8315 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 567us/step - loss: 1.1275 - accuracy: 0.7664\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 1s 650us/step - loss: 3.5559 - accuracy: 0.8732\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 1.0290 - accuracy: 0.7535\n",
      "764/764 [==============================] - 0s 439us/step\n",
      "764/764 [==============================] - 1s 657us/step - loss: 3.1707 - accuracy: 0.8717\n",
      "1222/1222 [==============================] - 1s 573us/step - loss: 0.5611 - accuracy: 0.8343\n",
      "764/764 [==============================] - 0s 440us/step\n",
      "764/764 [==============================] - 2s 653us/step - loss: 4.1573 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 559us/step - loss: 1.5302 - accuracy: 0.6385\n",
      "764/764 [==============================] - 0s 441us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 2.6376 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 567us/step - loss: 0.9768 - accuracy: 0.6692\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 1s 659us/step - loss: 2.6744 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 565us/step - loss: 2.4255 - accuracy: 0.6775\n",
      "764/764 [==============================] - 0s 471us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 5.0453 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.3328 - accuracy: 0.8615\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 657us/step - loss: 3.4433 - accuracy: 0.8733\n",
      "1222/1222 [==============================] - 1s 577us/step - loss: 0.4383 - accuracy: 0.8514\n",
      "764/764 [==============================] - 0s 441us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 4.4430 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 0.9175 - accuracy: 0.7983\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 2s 651us/step - loss: 3.5525 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 0.6217 - accuracy: 0.8084\n",
      "764/764 [==============================] - 0s 441us/step\n",
      "764/764 [==============================] - 2s 667us/step - loss: 3.8872 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 580us/step - loss: 0.3605 - accuracy: 0.8757\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 645us/step - loss: 4.0895 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 576us/step - loss: 0.6782 - accuracy: 0.7581\n",
      "764/764 [==============================] - 0s 439us/step\n",
      "764/764 [==============================] - 2s 653us/step - loss: 2.9350 - accuracy: 0.8723\n",
      "1222/1222 [==============================] - 1s 576us/step - loss: 2.2528 - accuracy: 0.5586\n",
      "764/764 [==============================] - 0s 451us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 2.9196 - accuracy: 0.8717\n",
      "1222/1222 [==============================] - 1s 576us/step - loss: 1.5927 - accuracy: 0.7594\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 1s 649us/step - loss: 3.2434 - accuracy: 0.8728\n",
      "1222/1222 [==============================] - 1s 582us/step - loss: 0.5222 - accuracy: 0.8313\n",
      "764/764 [==============================] - 1s 464us/step\n",
      "764/764 [==============================] - 1s 661us/step - loss: 3.8610 - accuracy: 0.8734\n",
      "1222/1222 [==============================] - 1s 574us/step - loss: 0.9764 - accuracy: 0.6937\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 2.8046 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 0.3943 - accuracy: 0.8336\n",
      "764/764 [==============================] - 0s 442us/step\n",
      "764/764 [==============================] - 1s 649us/step - loss: 3.5599 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 584us/step - loss: 0.7346 - accuracy: 0.7532\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 3.1409 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 575us/step - loss: 0.5749 - accuracy: 0.8513\n",
      "764/764 [==============================] - 0s 461us/step\n",
      "764/764 [==============================] - 2s 655us/step - loss: 4.0640 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 572us/step - loss: 0.8095 - accuracy: 0.7633\n",
      "764/764 [==============================] - 0s 446us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.2131 - accuracy: 0.8718\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.8118 - accuracy: 0.7917\n",
      "764/764 [==============================] - 0s 467us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 5.1154 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.5375 - accuracy: 0.8221\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 3.6183 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 0.9419 - accuracy: 0.6940\n",
      "764/764 [==============================] - 0s 446us/step\n",
      "764/764 [==============================] - 2s 647us/step - loss: 2.9785 - accuracy: 0.8729\n",
      "1222/1222 [==============================] - 1s 659us/step - loss: 1.1675 - accuracy: 0.7562\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 1s 645us/step - loss: 3.6633 - accuracy: 0.8730\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 1.3153 - accuracy: 0.6706\n",
      "764/764 [==============================] - 0s 440us/step\n",
      "764/764 [==============================] - 2s 653us/step - loss: 2.9822 - accuracy: 0.8727\n",
      "1222/1222 [==============================] - 1s 570us/step - loss: 0.3602 - accuracy: 0.8643\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.6607 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 0.5824 - accuracy: 0.8098\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 1s 648us/step - loss: 3.0754 - accuracy: 0.8720\n",
      "1222/1222 [==============================] - 1s 562us/step - loss: 1.1284 - accuracy: 0.6547\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 660us/step - loss: 2.4234 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 613us/step - loss: 0.6690 - accuracy: 0.8232\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 2s 645us/step - loss: 3.7861 - accuracy: 0.8713\n",
      "1222/1222 [==============================] - 1s 579us/step - loss: 0.7257 - accuracy: 0.8063\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 3.9750 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 569us/step - loss: 0.4378 - accuracy: 0.8409\n",
      "764/764 [==============================] - 0s 440us/step\n",
      "764/764 [==============================] - 2s 644us/step - loss: 3.4229 - accuracy: 0.8716\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 0.5493 - accuracy: 0.8106\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 2s 649us/step - loss: 3.9351 - accuracy: 0.8729\n",
      "1222/1222 [==============================] - 1s 599us/step - loss: 0.7441 - accuracy: 0.8004\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 1s 657us/step - loss: 3.1854 - accuracy: 0.8725\n",
      "1222/1222 [==============================] - 1s 617us/step - loss: 0.4557 - accuracy: 0.8397\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 642us/step - loss: 3.9909 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 566us/step - loss: 0.5407 - accuracy: 0.8334\n",
      "764/764 [==============================] - 0s 436us/step\n",
      "764/764 [==============================] - 1s 644us/step - loss: 3.9822 - accuracy: 0.8719\n",
      "1222/1222 [==============================] - 1s 572us/step - loss: 1.3444 - accuracy: 0.7040\n",
      "764/764 [==============================] - 0s 447us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 4.0460 - accuracy: 0.8722\n",
      "1222/1222 [==============================] - 1s 564us/step - loss: 1.2151 - accuracy: 0.6865\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 726us/step - loss: 2.9247 - accuracy: 0.8721\n",
      "1222/1222 [==============================] - 1s 588us/step - loss: 1.4747 - accuracy: 0.6761\n",
      "764/764 [==============================] - 0s 438us/step\n",
      "764/764 [==============================] - 2s 703us/step - loss: 2.7759 - accuracy: 0.8724\n",
      "1222/1222 [==============================] - 1s 588us/step - loss: 1.0533 - accuracy: 0.7151\n",
      "764/764 [==============================] - 0s 456us/step\n",
      "764/764 [==============================] - 2s 674us/step - loss: 3.4569 - accuracy: 0.8729\n",
      "1222/1222 [==============================] - 1s 618us/step - loss: 0.8884 - accuracy: 0.7931\n",
      "764/764 [==============================] - 0s 471us/step\n",
      "764/764 [==============================] - 2s 689us/step - loss: 3.5722 - accuracy: 0.8717\n",
      "1222/1222 [==============================] - 1s 615us/step - loss: 0.9265 - accuracy: 0.7616\n",
      "764/764 [==============================] - 0s 470us/step\n",
      "764/764 [==============================] - 2s 686us/step - loss: 3.5518 - accuracy: 0.8713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganblr.models.ganblr.GANBLR at 0x248d6d9b880>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ganblr import GANBLR\n",
    "model = GANBLR()\n",
    "model.fit(X_train, y_train, k=0, batch_size=32, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828211bb4a5649c59b8bca9559a76b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4867c900854a748391efd1632031a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004951eb4c19487a84e383f2ff15e331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_score_lr = model.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = model.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf = model.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "trtr_score_lr  = LogisticRegression().fit(X_train, y_train).score(X_test, y_test)\n",
    "trtr_score_rf  = RandomForestClassifier().fit(X_train, y_train).score(X_test, y_test)\n",
    "trtr_score_mlp = MLPClassifier().fit(X_train, y_train).score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Evaluate Item</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>MLP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSTR</td>\n",
       "      <td>0.759306</td>\n",
       "      <td>0.783056</td>\n",
       "      <td>0.759838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRTR</td>\n",
       "      <td>0.809713</td>\n",
       "      <td>0.849146</td>\n",
       "      <td>0.844847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Evaluate Item        LR        RF       MLP\n",
       "0          TSTR  0.759306  0.783056  0.759838\n",
       "1          TRTR  0.809713  0.849146  0.844847"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_evaluate = pd.DataFrame([\n",
    "    ['TSTR', acc_score_lr, acc_score_rf, acc_score_mlp],\n",
    "    ['TRTR', trtr_score_lr,trtr_score_rf,trtr_score_mlp]\n",
    "], columns=['Evaluate Item', 'LR', 'RF', 'MLP'])\n",
    "df_evaluate\n",
    "#df_evaluate.set_index('Evaluate Item')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ganblr import GANBLRPP\n",
    "\n",
    "from pandas import DataFrame, read_csv\n",
    "df = read_csv('../uci-datasets/raw_csv/adult.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39.0</td>\n",
       "      <td>5</td>\n",
       "      <td>77516.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>83311.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>215646.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.0</td>\n",
       "      <td>0</td>\n",
       "      <td>234721.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>338409.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>215419.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>64.0</td>\n",
       "      <td>8</td>\n",
       "      <td>321403.0</td>\n",
       "      <td>3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>374983.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83891.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>35.0</td>\n",
       "      <td>2</td>\n",
       "      <td>182148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  workclass    fnlwgt  education  education-num  marital-status  \\\n",
       "0      39.0          5   77516.0          0           13.0               2   \n",
       "1      50.0          1   83311.0          0           13.0               0   \n",
       "2      38.0          0  215646.0          3            9.0               1   \n",
       "3      53.0          0  234721.0          2            7.0               0   \n",
       "4      28.0          0  338409.0          0           13.0               0   \n",
       "...     ...        ...       ...        ...            ...             ...   \n",
       "48837  39.0          0  215419.0          0           13.0               1   \n",
       "48838  64.0          8  321403.0          3            9.0               4   \n",
       "48839  38.0          0  374983.0          0           13.0               0   \n",
       "48840  44.0          0   83891.0          0           13.0               1   \n",
       "48841  35.0          2  182148.0          0           13.0               0   \n",
       "\n",
       "       occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0               8             3     0    1        2174.0           0.0   \n",
       "1               4             2     0    1           0.0           0.0   \n",
       "2               6             3     0    1           0.0           0.0   \n",
       "3               6             2     4    1           0.0           0.0   \n",
       "4               5             0     4    0           0.0           0.0   \n",
       "...           ...           ...   ...  ...           ...           ...   \n",
       "48837           5             3     0    0           0.0           0.0   \n",
       "48838          14             4     4    1           0.0           0.0   \n",
       "48839           5             2     0    1           0.0           0.0   \n",
       "48840           8             1     1    1        5455.0           0.0   \n",
       "48841           4             2     0    1           0.0           0.0   \n",
       "\n",
       "       hours-per-week  native-country  class  \n",
       "0                40.0               0      1  \n",
       "1                13.0               0      1  \n",
       "2                40.0               0      1  \n",
       "3                40.0               0      1  \n",
       "4                40.0              12      1  \n",
       "...               ...             ...    ...  \n",
       "48837            36.0               0      1  \n",
       "48838            40.0               0      1  \n",
       "48839            50.0               0      1  \n",
       "48840            40.0               0      1  \n",
       "48841            60.0               0      0  \n",
       "\n",
       "[48842 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numerical_columns = np.argwhere(df.dtypes.values.ravel() == float).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4, 10, 11, 12], dtype=int64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ganblrpp = GANBLRPP(numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, y = df.values[:,:-1], df.values[:,-1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikaya\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:277: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n",
      "c:\\Users\\mikaya\\anaconda3\\lib\\site-packages\\sklearn\\mixture\\_base.py:277: ConvergenceWarning: Initialization 1 did not converge. Try different init parameters, or increase max_iter, tol or check for degenerate data.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32 int32\n",
      "764/764 [==============================] - 2s 657us/step - loss: 0.4262 - accuracy: 0.7974\n",
      "1222/1222 [==============================] - 1s 557us/step - loss: 0.6965 - accuracy: 0.7859\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 1s 657us/step - loss: 4.3747 - accuracy: 0.8438\n",
      "1222/1222 [==============================] - 1s 568us/step - loss: 0.4815 - accuracy: 0.8712\n",
      "764/764 [==============================] - 0s 437us/step\n",
      "764/764 [==============================] - 2s 646us/step - loss: 4.2792 - accuracy: 0.8491\n",
      "1222/1222 [==============================] - 1s 562us/step - loss: 1.5916 - accuracy: 0.6506\n",
      "764/764 [==============================] - 0s 426us/step\n",
      "764/764 [==============================] - 2s 648us/step - loss: 3.8955 - accuracy: 0.8516\n",
      "1222/1222 [==============================] - 1s 558us/step - loss: 0.4930 - accuracy: 0.8846\n",
      "764/764 [==============================] - 0s 431us/step\n",
      "764/764 [==============================] - 1s 655us/step - loss: 4.6107 - accuracy: 0.8532\n",
      "1222/1222 [==============================] - 1s 557us/step - loss: 0.4510 - accuracy: 0.8436\n",
      "764/764 [==============================] - 0s 428us/step\n",
      "764/764 [==============================] - 2s 653us/step - loss: 4.9541 - accuracy: 0.8546\n",
      "1222/1222 [==============================] - 1s 557us/step - loss: 0.7496 - accuracy: 0.7987\n",
      "764/764 [==============================] - 0s 424us/step\n",
      "764/764 [==============================] - 2s 651us/step - loss: 4.4271 - accuracy: 0.8534\n",
      "1222/1222 [==============================] - 1s 565us/step - loss: 0.4022 - accuracy: 0.8612\n",
      "764/764 [==============================] - 0s 426us/step\n",
      "764/764 [==============================] - 1s 648us/step - loss: 3.6912 - accuracy: 0.8541\n",
      "1222/1222 [==============================] - 1s 563us/step - loss: 0.7206 - accuracy: 0.8221\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 2s 655us/step - loss: 5.3119 - accuracy: 0.8540\n",
      "1222/1222 [==============================] - 1s 559us/step - loss: 0.5818 - accuracy: 0.8325\n",
      "764/764 [==============================] - 0s 432us/step\n",
      "764/764 [==============================] - 2s 659us/step - loss: 3.6898 - accuracy: 0.8538\n",
      "1222/1222 [==============================] - 1s 571us/step - loss: 0.2309 - accuracy: 0.9195\n",
      "764/764 [==============================] - 0s 433us/step\n",
      "764/764 [==============================] - 1s 647us/step - loss: 5.0090 - accuracy: 0.8543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ganblr.models.ganblr.GANBLR at 0x1d75ba90a60>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ganblrpp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e050136a7d9c4b10acf09a3d94dfcb5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499e277024f746af82a4b3b2750f0c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mikaya\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e572fcff1a44a0a07f0d6a0a8bb938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_score_lr  = ganblrpp.evaluate(X_test, y_test, model='lr')\n",
    "acc_score_mlp = ganblrpp.evaluate(X_test, y_test, model='mlp')\n",
    "acc_score_rf  = ganblrpp.evaluate(X_test, y_test, model='rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 of 2: Sampling discrete data from GANBLR.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee96ab26d0e045ff9e4c226b90bb2924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2 of 2: Sampling numerical data.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "dispatcher for __array_function__ did not return an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Repos\\ganblr-opensource\\usage_example.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Repos/ganblr-opensource/usage_example.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m syn_data \u001b[39m=\u001b[39m ganblrpp\u001b[39m.\u001b[39;49msample()\n",
      "File \u001b[1;32mc:\\Repos\\ganblr-opensource\\ganblr\\models\\ganblrpp.py:232\u001b[0m, in \u001b[0;36mGANBLRPP.sample\u001b[1;34m(self, size, verbose)\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mstep 2 of 2: Sampling numerical data.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    231\u001b[0m numerical_columns \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numerical_columns\n\u001b[1;32m--> 232\u001b[0m numerical_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__discritizer\u001b[39m.\u001b[39;49minverse_transform(syn_x[:,numerical_columns], n_jobs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    233\u001b[0m syn_x[:,numerical_columns] \u001b[39m=\u001b[39m numerical_data\n\u001b[0;32m    234\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mhstack([syn_x, syn_y])\n",
      "File \u001b[1;32mc:\\Repos\\ganblr-opensource\\ganblr\\models\\ganblrpp.py:133\u001b[0m, in \u001b[0;36mDMMDiscritizer.inverse_transform\u001b[1;34m(self, x, n_jobs, verbose)\u001b[0m\n\u001b[0;32m    130\u001b[0m         inversed_x[cur_mode_idx] \u001b[39m=\u001b[39m sample_results\n\u001b[0;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m inversed_x\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m inversed_data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mhstack(Parallel(n_jobs\u001b[39m=\u001b[39;49mn_jobs, verbose\u001b[39m=\u001b[39;49mverbose))(delayed(__parallel_unit)(i, mu, sigma)\n\u001b[0;32m    134\u001b[0m     \u001b[39mfor\u001b[39;00m i, (mu, sigma) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__arr_mu, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__arr_sigma))\n\u001b[0;32m    136\u001b[0m \u001b[39m#for i, (mu, sigma) in enumerate(zip(\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[39m#    self.__arr_mu, \u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[39m#    self.__arr_sigma)):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[39m#    \u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39m#    inversed_data.append(inversed_x.reshape(-1, 1))\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__scaler\u001b[39m.\u001b[39minverse_transform(inversed_data)\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mhstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: dispatcher for __array_function__ did not return an iterable"
     ]
    }
   ],
   "source": [
    "syn_data = ganblrpp.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5bbedb5fa720de9fc907ceb56d89ea952339fe8fd12ba55975f895c345e9c974"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
